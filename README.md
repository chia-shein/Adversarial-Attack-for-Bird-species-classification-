# Adversarial-Attack-for-Bird-species-classification
![](./readme_img/testset.png)

## Adversarial Attack Description:
An adversarial example is an input to a machine learning model that is purposely designed to cause a model to make a mistake in its predictions despite resembling a valid input to a human.

![](./readme_img/adversarial.png)

* Image is taken from [here](https://towardsdatascience.com/breaking-neural-networks-with-adversarial-attacks-f4290a9a45aa)


## Dependencies
```shell
pip install keras
```
## Datasets
* Found 43622 images belonging to 300 classes inside the training dataset.
* 

## Code
#### train.py
```shell
  python train.py
```
* Adding the noise on the images to make them look like they have been adversarial attacks.
* Augmentation of the images with adding noise to make the model more robust.

#### Inference.py

## Experiment Result
